{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95992c8a-141a-47c8-bf7c-87e57ebd79da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer,GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01004c11-f1dd-476d-afae-d716f2d3a854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b27b08-0b96-4435-8f14-d782bd8cc62e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005206108093261719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343b07bcf18842a7824d48915de97239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_map = \"auto\"\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "### load model after fine tuned on alpaca datasets\n",
    "model = PeftModel.from_pretrained(model, \"Nelsonlin0321/alpaca-lora-7b-tuned-on-hk-cvs-fqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c16912f-1e16-4644-b966-933a0e26cdfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\")\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c540c805-7fcd-472f-971f-cf1290222338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt_eval(instruction):\n",
    "    template =  f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Response:\"\"\"\n",
    "    return template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48288bc-f4f0-4ce5-b516-d8706e08e831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_generation_config = GenerationConfig(\n",
    "    temperature=0.1,\n",
    "    top_p=0.75,\n",
    "    num_beams=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e58aa9-e4a4-4a3e-b928-afd447612f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_answer(instruction):\n",
    "    prompt = generate_prompt_eval(instruction)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=eval_generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "    for s in generation_output.sequences:\n",
    "        output = tokenizer.decode(s)\n",
    "        # print(output)\n",
    "        print(\"Response:\", output.split(\"### Response:\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0782ffd-ba86-46ec-8d6b-212f422bde5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"Who are eligible to be disbursed with the first-instalment voucher of $1,500 on 16 April?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43732618-76f6-455d-8a12-519d4c8f8927",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: All eligible people who have successfully registered under 2022 CVS and met the relevant eligibility criteria will be disbursed with the first-instalment voucher of $1,500 on 16 April.\n"
     ]
    }
   ],
   "source": [
    "generate_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f1eef-d486-473c-a55b-d999d1107280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
